Title: Startups and PhDs
Date: 2015-10-15
Status: draft
Category: Thoughts
Tags: startup, research, phd
Slug: startups-and-phds
Summary: FILLME

(Or, how PhDs are startups ignoring themselves.)

I just came back from visiting [a friend](http://nicholas.charriere.com/) in San Francisco, and discovered a little more about the startup scene during the trip. Since then my daily podcast is Sam Altmann's course on [How to Start a Startup](http://startupclass.samaltman.com/), and the number of parallels there are between starting a startup and doing a PhD is mind-boggling!

## The development loop

The core process behind creating a startup is the *develop-product-evaluate-with-users* loop.
Naturally it's not all there is to it, but a huge part of Sam's course involves tricks and advice to keep that loop at the centre of your preoccupations, and keep it as short as possible.
Which also resonates a lot with programming: anybody who's moved from a compiled language (or worse, compile+deploy like for Android) to e.g. web development, where you have things like live-reload or live-editing, will agree: the shorter your development loop, the more you're really interacting with a system that shows you the bugs as you write them.
The longer the loop, the more work you'll pack between each *let's-compile-and-try-it-out*, and the more problems you introduce without seeing them, until days or weeks later you notice something's wrong, and by that time your bug has usually grown nice stealthy roots all over the place.
Imagine writing a blog post without being able to see your text as you write, but only once it's complete.
And then you can correct, but only see it entirely again once it's complete.
That's what it's like to develop in an environment with long iteration loops.
(For more about this, watch Bret Victor's [Inventing on Principle](https://vimeo.com/36579366).)

Now research has the same problem, at several levels.
When creating an experiment or a simulation, you should test fast.
*Fast* fast.
As if you were a startup and your investors wanted feedback in a week.
It helps catching mistakes early on, it helps refining questions, it's good all over.
(The first time I heard this piece of advice I really underestimated its importance.)
But the same goes for the *scientific conversation loop*, which nowadays looks like this:

* do research (many loops in here),
* write paper,
* submit to journal,
* receive reviews,
* correct and resubmit,
* get published,
* get cited and discussed.

"Arg!", you say? My sentiments entirely.

In the best cases I've seen this cycle is a few weeks long, but usually it's several months, and up to a year or more at the very beginning of your research (which, incidentally, is also when long cycles are the most damaging, since you're exploring your field).

There's nothing necessary about this: I believe such long cycles are the product of history and the way practices and tools developed (the same goes for programming), but it serves no purpose in research and science in general to have long loops forced onto people.
And not only are long loops the standard, it's also really hard to have a short loop if you want one (setting aside the fact that it's not standard).
Now no amount of secrecy, embargo on your ideas or results, or need for free time and breathing space to develop a long-term project, is incompatible with the possibility of short conversation loops.

(One could say conferences are an occasion for shorter loops, but you still need to enter the community, and at best the loop is about a third shorter.)

To me, this explains quite a few PhD students' headaches, and it's an integral part of the changes academia should be processing.
(There's more to all this, and we'll talk more about it in other posts.)

## Pivoting
